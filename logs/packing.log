[2025-06-20 22:34:28,725] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-20 22:34:28,845] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-20 22:34:29,999] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
Starting at: 2025-06-20 22:34:30.553456

1. Initializing actor ...
Initializing actor model for debugging...
Note: Running in standalone mode (no distributed training)
Using model: meta-llama/Llama-3.1-8B-Instruct
Flash Attention: False
BF16: True
PyTorch Compile: False
Packing Samples: True
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 103.50it/s]
Actor model initialized successfully!
Actor model parameters: 8030261248
Actor model moved to GPU: 0
Tokenizer configured. Vocab size: 128256
Actor initialized successfully on device: 0

2. Loading input dump ...

3. Replaying an input ...

=== Replaying Input ===
Source: actor_inputs_rank0_20250619_052658_128923.pkl
Timestamp: 20250619_052658_128923
Rank: 0
Batch size: 2
Sequence length: 1259
[INFO 06-20 22:34:35.602 actor.py:213] [localhost][805385][rNA] Actor forward start. sequences=torch.Size([1, 2328])  padded_sequences=torch.Size([1, 2328]) stride (1, 1) storage_offset 0 foward_attention_mask=None position_ids=torch.Size([1, 2328]) padded_position_ids=torch.Size([1, 2328]) stride (1, 1) storage_offset 0
[INFO 06-20 22:34:35.602 actor.py:213] [localhost][805385][rNA] Actor forward start. sequences=torch.Size([1, 2328])  padded_sequences=torch.Size([1, 2328]) stride (1, 1) storage_offset 0 foward_attention_mask=None position_ids=torch.Size([1, 2328]) padded_position_ids=torch.Size([1, 2328]) stride (1, 1) storage_offset 0
[INFO 06-20 22:34:36.142 actor.py:216] [localhost][805385][rNA] Actor forward end
[INFO 06-20 22:34:36.142 actor.py:216] [localhost][805385][rNA] Actor forward end
Replay successful!
DEBUG:filelock:Attempting to acquire lock 123204286839952 on /home/mtanaka/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
DEBUG:filelock:Lock 123204286839952 acquired on /home/mtanaka/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
DEBUG:filelock:Attempting to release lock 123204286839952 on /home/mtanaka/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
DEBUG:filelock:Lock 123204286839952 released on /home/mtanaka/.triton/autotune/Fp16Matmul_2d_kernel.pickle.lock
DEBUG:filelock:Attempting to acquire lock 123204368353936 on /home/mtanaka/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
DEBUG:filelock:Lock 123204368353936 acquired on /home/mtanaka/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
DEBUG:filelock:Attempting to release lock 123204368353936 on /home/mtanaka/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
DEBUG:filelock:Lock 123204368353936 released on /home/mtanaka/.triton/autotune/Fp16Matmul_4d_kernel.pickle.lock
